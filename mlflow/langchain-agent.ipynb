{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain Agents with MLflow\n",
    "\n",
    "Welcome to an engaging and educational tutorial designed to dive deep into the world of LangChain agents and their integration with MLflow. This notebook-based tutorial is tailored to offer a practical and comprehensive understanding of LangChain agents and their practical applications with a modest dose of absurdity.\n",
    "\n",
    "### What This Tutorial Covers\n",
    "\n",
    "- **Understanding LangChain Agents**: Gain insights into what LangChain agents are and how they function in complex decision-making scenarios.\n",
    "- **Introduction to MLflow Integration**: Explore how LangChain integrates with MLflow, a powerful tool for the lifecycle management of machine learning models.\n",
    "\n",
    "### Background on LangChain and Agents\n",
    "\n",
    "- **LangChain Overview**: LangChain is a Python framework designed to simplify the creation and deployment of applications powered by language models, particularly in tasks requiring contextual understanding and decision-making.\n",
    "- **Agents in LangChain**: Agents are dynamic components within LangChain that use language models to decide on sequences of actions based on given objectives and available tools. Unlike static workflows, agents can adapt their responses and strategies based on the evolving context.\n",
    "\n",
    "### Integration with MLflow\n",
    "\n",
    "- **MLflow's Role**: In this tutorial, MLflow plays a crucial role in logging, tracking, and deploying the LangChain agent. You'll learn how to effectively use MLflow to manage the lifecycle of your LangChain agent, ensuring a streamlined process from development to deployment.\n",
    "\n",
    "### Tutorial Overview\n",
    "\n",
    "In this tutorial, we will:\n",
    "\n",
    "1. **Initialize a LangChain Agent**: Set up an agent with specific tools and a language model, ready to tackle our chosen task.\n",
    "2. **Log and Load the Agent Model with MLflow**: Demonstrate the process of logging the agent in MLflow and then loading it for execution.\n",
    "3. **Run a Real-World Prediction**: Use the agent to determine how much snow would result from the latest year's rainfall in Raleigh, NC, and conceptualize the size of a snowman that could be built with it.\n",
    "\n",
    "By the end of this tutorial, you will have a solid grasp of LangChain agents and MLflow's capabilities in enhancing these agents' development and deployment.\n",
    "\n",
    "Let’s embark on this exciting journey into the realm of LangChain agents and MLflow!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "In our LangChain Agents tutorial, we leverage an important dependency known as `SerpAPI`. This tool is pivotal in providing our LangChain agent with API access to various search engines, crucial for retrieving real-time data from the web.\n",
    "\n",
    "#### Installing SerpAPI\n",
    "\n",
    "To use SerpAPI, you'll need to install it via pip. It's a straightforward process, and the package is named `google-search-results`. Once installed, you can create an account at [SerpAPI's Official Website](https://serpapi.com/) and retrieve an API Key. In order to use this integration with LangChain, you can simply load the toolset via `load_tools([\"serpapi\"])` to allow the LangChain agent access to the Google Search APIs.\n",
    "\n",
    "```\n",
    "    pip install google-search-results\n",
    "```\n",
    "\n",
    "As we move forward in the tutorial, we will explore how to effectively use SerpAPI to empower our LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "assert \"OPENAI_API_KEY\" in os.environ, \"Please set the OPENAI_API_KEY environment variable.\"\n",
    "assert \"SERPAPI_API_KEY\" in os.environ, \"Please set the SERPAPI_API_KEY environment variable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the LangChain Agent with Tools and OpenAI LLM\n",
    "\n",
    "In this part of the tutorial, we delve into the initialization of a LangChain agent, a key step in building our application. This process involves configuring the language model and defining the tools that the agent will utilize to perform its tasks.\n",
    "\n",
    "#### Language Model Configuration\n",
    "\n",
    "- **OpenAI LLM**: We initialize the OpenAI language model (`llm`) with a specific temperature setting. The temperature parameter controls the randomness of the language model's responses, with a lower value leading to more predictable and conservative outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The LangChain OpenAI wrapper uses `text-davinci-003` as the default model type as of version 0.0.331\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Tools for the Agent\n",
    "\n",
    "- **Tool Selection**: The agent is equipped with two primary tools – a web search engine interface (`serpapi`) and a math execution engine (`llm-math`). These tools are crucial for enabling the agent to retrieve information from the web and perform mathematical computations, respectively.\n",
    "- **Tool Loading**: The `load_tools` function is used to load these tools and associate them with our language model. This integration ensures that the agent has the necessary capabilities to handle complex queries that involve both data retrieval and quantitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the two tools that the agent will use: a web search engine interface and a math execution engine.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Initialization\n",
    "\n",
    "- **Agent Type**: We create the agent using the `initialize_agent` function and specify the type of agent as `ZERO_SHOT_REACT_DESCRIPTION`. This particular type of agent is designed to react and provide descriptions based on zero-shot learning, meaning it can understand and respond to tasks without prior specific training on them.\n",
    "- **Verbose Mode**: The agent is initialized in verbose mode, which allows us to see detailed logs of its decision-making process. This feature is particularly useful for understanding how the agent interprets and responds to different inputs.\n",
    "\n",
    "Through this setup, we have laid the foundation for an intelligent LangChain agent capable of handling a variety of tasks by leveraging the power of language models and specific functional tools. As we progress, we will see this agent in action, demonstrating its potential in practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and Loading the LangChain Agent Using MLflow\n",
    "\n",
    "In this crucial phase of our tutorial, we focus on the integration of the LangChain agent with MLflow. This process involves logging the agent model in MLflow and subsequently loading it for use.\n",
    "\n",
    "#### Logging the Agent in MLflow\n",
    "\n",
    "- **Starting an MLflow Run**: We initiate an MLflow run, a key step in MLflow's tracking system, which is used to organize and manage model development activities.\n",
    "- **Model Logging**: The agent is logged into MLflow using the `mlflow.langchain.log_model` function. This function not only saves the agent model but also tags it with a specified name, in our case, \"search-calculation\".\n",
    "\n",
    "#### Loading the Model for Use\n",
    "\n",
    "- **Model Retrieval**: Post logging, we load the model using MLflow's `pyfunc.load_model` function. This step is essential for activating the agent model, making it ready for executing predictions or tasks.\n",
    "- **Model URI**: The `model_info.model_uri` provides the unique identifier for the logged model, ensuring that we are loading the correct version of the agent model for our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepartion for Logging\n",
    "\n",
    "A good practice to follow, prior to logging a model, is to validate the model's input and output signature. This can be used to explicitly define the expected signature during model logging to ensure that inference with the model is validated properly. \n",
    "\n",
    "We can define the signature by passing in an example input to our model and generating a signature inference based on these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = {\n",
    "    \"input\": \"How many apples can fit inside a standard 8 cubic meter cement mixer truck's drum?\"\n",
    "}\n",
    "\n",
    "prediction = agent.run(input_example)\n",
    "\n",
    "signature = infer_signature(input_example, prediction)\n",
    "\n",
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the math is off by about an order of magnitude, we do have our input and output signature, which we will use when logging the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Google Agent\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        lc_model=agent,\n",
    "        artifact_path=\"search-calculation\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        extra_pip_requirements=[\"google-search-results==2.4.2\"],\n",
    "    )\n",
    "\n",
    "# Load our agent model for use\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we open up the MLflow UI, we can see our model with our signature and our input example that we defined.\n",
    "\n",
    "![Google Agent in the MLflow UI](https://i.imgur.com/NdOObEf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Agent Prediction and Result Analysis\n",
    "\n",
    "In this segment of the tutorial, we utilize our loaded LangChain agent model to make a prediction. The agent is tasked with determining the volume of snow resulting from rainfall in Raleigh, NC, and conceptualizing the size of a snowman that could be built from this snow.\n",
    "\n",
    "#### Agent Prediction Task\n",
    "\n",
    "The agent receives a complex query that involves several steps:\n",
    "- Determining the most recent year's rainfall in Raleigh, NC.\n",
    "- Converting this rainfall amount into snow, using a depth conversion ratio of snow to rain.\n",
    "- Calculating the total volume of snow for 1 acre of land.\n",
    "- Estimating the size of a snowman that could be made from this volume of snow.\n",
    "\n",
    "#### Result Analysis\n",
    "\n",
    "The agent's output demonstrates its ability to:\n",
    "- Navigate through complex queries involving multiple steps.\n",
    "- Integrate search and calculation tools to derive accurate and relevant information.\n",
    "- Translate quantitative data into a practical and imaginative scenario.\n",
    "\n",
    "#### Conclusion of Agent's Task\n",
    "\n",
    "The agent successfully completes its task by providing a comprehensive answer, showcasing the practical utility of LangChain agents in processing and synthesizing information to answer multifaceted queries. This example illustrates the power of integrating advanced language models with specialized tools to solve real-world problems in creative and informative ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response = loaded_model.predict(\n",
    "    [\n",
    "        {\n",
    "            \"input\": \"How much rain has fallen in Raleigh, NC for the most recent year? \"\n",
    "            \"If that rain fell as snow, which has a depth conversion of snow to rain of 10 to 1, what is the total \"\n",
    "            \"volume of snow in cubic feet for 1 acre of land?\"\n",
    "            \"How big of a snowman could I make if I used all of that snow?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Number of Standard Snowmen with LangChain Agent\n",
    "\n",
    "In this section, we utilize the loaded LangChain agent model to compute the number of standard snowmen that can be made from a given volume of snow. This calculation is an extension of our previous query, demonstrating the agent's ability to engage in sequential reasoning and complex calculations.\n",
    "\n",
    "#### Agent's Calculation Task\n",
    "\n",
    "The agent is tasked with a new query:\n",
    "- To determine how many standard snowmen could be made from 27,965,520 cubic feet of snow.\n",
    "\n",
    "#### Verbose Mode Output and Analysis\n",
    "\n",
    "With verbose mode active, we observe the agent's step-by-step approach:\n",
    "\n",
    "- **Initial Query Understanding**: The agent recognizes the need to determine the volume of a standard snowman.\n",
    "- **Search for Standard Snowman Volume**: It performs a web search to find the volume of a standard snowman.\n",
    "- **Observation and Calculation**: The agent finds relevant data and calculates the volume of a standard snowman based on given dimensions.\n",
    "- **Final Answer**: After obtaining the volume of a single snowman, the agent divides the total snow volume by the volume of one snowman to find the total number of snowmen that can be made.\n",
    "\n",
    "#### Agent's Output\n",
    "\n",
    "The agent concludes that approximately 327,072.8 standard snowmen could be made from the given volume of snow. This result showcases the agent's capability to:\n",
    "- Conduct targeted searches and extract pertinent information from various sources.\n",
    "- Perform mathematical calculations and apply them to practical scenarios.\n",
    "- Provide comprehensive and quantitatively accurate responses to multi-faceted queries.\n",
    "\n",
    "#### Conclusion of the Agent's Task\n",
    "\n",
    "This exercise illustrates the advanced analytical and problem-solving skills of LangChain agents. It highlights the agent's proficiency in combining search and calculation tools to derive meaningful answers, emphasizing the practical applications of such agents in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_response = loaded_model.predict(\n",
    "    [{\"input\": \"How many standard snowmen could I make with 27965520 cubic feet of snow?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculated_response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of snowmen.\n",
    "\n",
    "![snowmen](https://i.imgur.com/Bzdub6n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, as the LLM put it, \"This amount of snow could make **a very large snowman**.\"\n",
    "\n",
    "![snowman](https://i.imgur.com/HiktkRQ.png)\n",
    "\n",
    "\n",
    "Indeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Images created with the use of [DALL·E 3](https://openai.com/dall-e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concluding Our LangChain Agents and MLflow Tutorial\n",
    "\n",
    "As we wrap up this fun tutorial, let's take a moment to reflect on the fascinating journey we've embarked on with LangChain agents and MLflow. We ventured through the realms of advanced language model applications, culminating in a whimsical yet insightful exploration of snowmen creation – a topic every child (and child-at-heart) has pondered!\n",
    "\n",
    "#### Key Takeaways from the Tutorial\n",
    "\n",
    "- **Versatility of LangChain Agents**: We've seen firsthand how LangChain agents can navigate complex tasks, from gathering real-time data to performing intricate calculations. Their ability to process and synthesize information from diverse sources is nothing short of impressive.\n",
    "- **Power of MLflow in Model Management**: MLflow has proven to be an invaluable asset in our journey. Its capabilities in tracking, logging, and deploying LangChain models have streamlined our workflow, making the management of complex machine learning processes more accessible and efficient.\n",
    "- **Seamless Integration**: The integration of LangChain with MLflow has demonstrated how two powerful tools can come together to create a robust framework for developing and deploying AI-driven applications.\n",
    "\n",
    "\n",
    "#### Wrapping Up with a Smile\n",
    "\n",
    "As we conclude, remember that the world of LangChain agents and MLflow is as vast as it is fascinating. Whether you're calculating snowmen, predicting weather patterns, or performing LLM-assisted competitive market analysis, the opportunities are boundless when it comes to creating powerful and complex agents.\n",
    "\n",
    "Thank you for joining us on this unique educational adventure. We hope it has sparked your curiosity and inspired you to delve deeper into the capabilities of LangChain and MLflow. Here's to many more fun and informative explorations in the world of machine learning!\n",
    "\n",
    "Happy coding, and may your snowmen always be perfectly calculated!\n",
    "\n",
    "### What's next?\n",
    "\n",
    "If you'd like to learn more about how MLflow and LangChain integrate, see the other [advanced tutorials for MLflow's LangChain flavor](https://www.mlflow.org/docs/latest/llms/langchain/index.html#advanced-tutorials)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
