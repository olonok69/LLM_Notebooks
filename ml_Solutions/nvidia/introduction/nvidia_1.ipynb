{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5006727b-8710-4945-9feb-d00c9839c28a",
   "metadata": {},
   "source": [
    "# NVIDIA AI Enterprise \n",
    "\n",
    "NVIDIA AI Enterprise is an end-to-end, cloud-native software platform that accelerates data science pipelines and streamlines development and deployment of production-grade co-pilots and other generative AI applications.  Easy-to-use microservices provide optimized model performance with enterprise-grade security, support, and stability to ensure a smooth transition from prototype to production for enterprises that run their businesses on AI.\n",
    "\n",
    "# NVIDIA  NIM\n",
    "\n",
    "NVIDIA NIM, part of NVIDIA AI Enterprise, is a set of accelerated inference microservices that allow organizations to run AI models on NVIDIA GPUs anywhere—in the cloud, data center, workstations, and PCs. Using industry-standard APIs, developers can deploy AI models with NIM using just a few lines of code. NIM containers seamlessly integrate with the Kubernetes (K8s) ecosystem, allowing efficient orchestration and management of containerized AI applications. Accelerate the development of your AI applications today with NIM.\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/llm-overview\n",
    "\n",
    "https://venturebeat.com/ai/meta-unleashes-its-most-powerful-ai-model-llama-3-1-with-405b-parameters/\n",
    "\n",
    "\n",
    "Llama 3.1 is multilingual and support English, Portuguese, Spanish, Italian, German, French, Hindi, and Thai prompts. The smaller Llama 3 models will also become multilingual starting today.\n",
    "\n",
    "Llama 3.1’s context window has been expanded to 128,000 tokens — which means users can feed it as much text as goes into a nearly 400 page novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c6e1b-d44a-4d8a-af2f-d7f106a35053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import os\n",
    "PATH = os.getcwd()\n",
    "Image(filename = os.path.join(PATH, \"coT.png\"), width=600, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21c3db-3ffe-406f-a33a-456026e1fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70671a0f-7274-488f-ae12-330997fc7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "nvapi_key=  os.getenv(\"NVIDIA_API_KEY\")\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = nvapi_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522275c-6683-4ff4-91fe-39624d9d06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt= \"\"\"   Read the Instruction below and provide an answer. \n",
    "Always provide an answer. If you dont know how to calculate something, respond please I dont know\n",
    "\n",
    " INSTRUCTION:\n",
    "Question:\n",
    "I bought a car 20 years ago, and its cost was 100000$.\n",
    "Car's anual depreciation it is 5%.\n",
    "Using the Percentage (Declining Balance) method, what it is the value of the car now ?\n",
    "\n",
    "### RESPONSE:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20989d-a2b2-4a0c-a8b7-f1021f5b4485",
   "metadata": {},
   "source": [
    "# meta/llama-3.1-405b-instruct\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/meta-llama-3_1-405b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c72f9-7309-4004-8b91-aaecbbb890b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"meta/llama-3.1-405b-instruct\",\n",
    "  messages=[{\"role\":\"user\",\"content\":Prompt}],\n",
    "  temperature=0.5,\n",
    "  top_p=0.7,\n",
    "  max_tokens=2048,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b1480-e3d3-4c69-a1a8-6ac615b87cf6",
   "metadata": {},
   "source": [
    "# microsoft/phi-3-mini-4k-instruct\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/microsoft-phi-3-mini-4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884829f-a6f1-4b77-9e44-c2c69e492987",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"microsoft/phi-3-mini-4k-instruct\",\n",
    "  messages=[{\"role\":\"user\",\"content\":Prompt}],\n",
    "  temperature=0.5,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb5968-4ce2-4022-918b-2559d0e71f61",
   "metadata": {},
   "source": [
    "# mistral-7b-instruct-v0.3\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/mistralai-mistral-7b-instruct-v03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ed56f-0d80-40b9-ad09-01df03949dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"mistralai/mistral-7b-instruct-v0.3\",\n",
    "  messages=[{\"role\":\"user\",\"content\":Prompt}],\n",
    "  temperature=0.5,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307595a-f940-4eb8-91ed-056f23d80cfe",
   "metadata": {},
   "source": [
    "# google/gemma-2-9b-it\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/google-gemma-2-9b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe7dff-d01c-4c2a-a1c4-da3143556866",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"google/gemma-2-9b-it\",\n",
    "  messages=[{\"role\":\"user\",\"content\":Prompt}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c53cad-4522-40b0-b205-7c73833a85d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sk)",
   "language": "python",
   "name": "sk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
