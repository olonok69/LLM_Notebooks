{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c0628-89d8-4e84-bf06-3c6e1c0d85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/olonok69/LLM_Notebooks/blob/main/Prompt_engineering/Mistral7_b_prompt_Engineering_Techniques.ipynb\n",
    "# https://github.com/olonok69/LLM_Notebooks/blob/main/mistral/Mistral7b_instruct_qlora_CoT_Fine_Tune_v2.ipynb\n",
    "\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview\n",
    "\n",
    "# pip install --upgrade google-cloud-aiplatform\n",
    "# gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6f4965-cc46-47d7-834a-c77ab3d2ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "681fdb83-dc25-4dd4-af53-52e2398a1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=config['PROJECT'], location=config['REGION'])\n",
    "parameters = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"max_output_tokens\": 1024,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40\n",
    "}\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186590a-cee9-46fe-b990-5736c137f830",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb5afa7-c61a-4aa9-b576-7ed26434161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: The answer is 100000 * 0.95 ^ 20 = 100000 * 0.00095 = 9.50$\n",
      "\n",
      "The car's value depreciates by 5% every year. So, after 20 years, the car's value will be 100000 * 0.95 ^ 20 = 9.50$.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "Question:\n",
    "I had a car 20 years ago, and its cost was 100000$.\n",
    "Car's anual rate depreciation is 5%. and no residual value\n",
    "Using the Declining Balance method, what it is the value of the car now ?\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a611757a-d8c7-40d4-b4c3-ccf3779e3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: The answer is 100000 * 0.95 ^ 20 = 100000 * 0.0367 = 3670$.\n",
      "\n",
      "The first step is to calculate the depreciation rate per year. This is done by dividing the annual rate of depreciation by 100. In this case, the annual rate of depreciation is 5%, so the depreciation rate per year is 5 / 100 = 0.05.\n",
      "\n",
      "The next step is to calculate the depreciation for each year. This is done by multiplying the value of the car by the depreciation rate per year. In this case, the value of the car is $100,000, so the depreciation for each year is $100,000 * 0.05 = $5,000.\n",
      "\n",
      "The final step is to calculate the value of the car after 20 years. This is done by subtracting the depreciation for each year from the value of the car. In this case, the value of the car after 20 years is $100,000 - $5,000 * 20 = $3670.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "Question:\n",
    "I had a car 20 years ago, and its cost was 100000$.\n",
    "Car's anual rate depreciation is 5%. and no residual value\n",
    "Using the Declining Balance method, what it is the value of the car now ?\n",
    "Let,s think step by step\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8ae624d-3505-41cd-9209-8ec682af5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step 1: Calculate the depreciation rate.**\n",
      "\n",
      "Depreciation rate = Annual depreciation rate * Number of years\n",
      "Depreciation rate = 5% * 20 years\n",
      "Depreciation rate = 100%\n",
      "\n",
      "**Step 2: Calculate the book value of the car after 20 years.**\n",
      "\n",
      "Book value = Original cost * (1 - Depreciation rate)^Number of years\n",
      "Book value = 100000$ * (1 - 100%)^20\n",
      "Book value = 100000$ * 0\n",
      "Book value = 0$\n",
      "\n",
      "**Therefore, the value of the car now is $0.**"
     ]
    }
   ],
   "source": [
    "def generate():\n",
    "\n",
    "  model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "  responses = model.generate_content(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "Question:\n",
    "I had a car 20 years ago, and its cost was 100000$.\n",
    "Car\\'s anual rate depreciation is 5%. and  it has no residual value.\n",
    "Using the Declining Balance method, what it is the value of the car now ?\n",
    "Let,s think step by step\"\"\",\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=True,\n",
    "  )\n",
    "  \n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3d968e-23a6-4d49-99d0-40b2f0b66e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: 849\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "In this task, you are given an input list A. You need to find all the elements of the list that are numbers and calculate their sum.\n",
    "\n",
    "['i', 'P', 'h', '849', 'e']\n",
    "\n",
    "\n",
    "### RESPONSE:\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b247879-9e7e-4d86-8a5b-04b9536d4b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: 10 - 2 - 2 = 6 apples.\n",
      "6 + 5 = 11 apples.\n",
      "11 - 1 = 10 apples.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "Question:\n",
    "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "Then I went again and bought 5 more apples and I ate 1 apple.\n",
    "Answer: How many apples did I remain with?\n",
    "\n",
    "### RESPONSE:\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2543b5b7-248a-4e38-ab1e-c4911f4505d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: 57\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "Question: I had a car 20 years ago and at that time I was 37. Answer: How old I am now?\n",
    "\n",
    "\n",
    "### RESPONSE:\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d1054-91ad-43e6-922f-ad14a1035d9f",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "898495a1-2642-41a2-a927-1f0a1490fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model:  The sentiment of the text is neutral. The text does not express any strong positive or negative emotion towards the vacation. The word \"okay\" is a neutral term that does not imply any strong feelings either way.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Classify the text into neutral, negative or positive.\n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:? \"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e7cde-1d54-4eed-bd12-d41dc3205147",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "785066c9-b648-4065-8490-66725b0c2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: The children were farduddeling around the room, laughing and having fun.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"A \"whatpu\" is a small, furry animal native to Tanzania. \n",
    "An example of a sentence that uses the word whatpu is: We were traveling in Africa and we saw these very cute whatpus.\n",
    "\n",
    "To do a \"farduddle\" means to jump up and down really fast.\n",
    "can you give me an example that uses the word farduddle :?\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6034435-1aae-43c3-a368-907a9ea10db2",
   "metadata": {},
   "source": [
    "# Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41bd4bfa-ac16-4c4f-89fa-41d62fafbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: Olivia bought 5 bagels for 3 each, so she spent 5 * 3 = 15 dollars. She has 23 - 15 = 8 dollars left. The answer is 8.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Question: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
    "there will be 21 trees. How many trees did the grove workers plant today?\n",
    "Answer: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
    "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
    "\n",
    "Question: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "Answer: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Question: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "Answer: Leah had 32 chocolates and Leahâ€™s sister had 42. That means there were originally 32 + 42 = 74\n",
    "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
    "\n",
    "Question: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
    "did Jason give to Denny?\n",
    "Answer: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
    "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
    "\n",
    "Question: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
    "he have now?\n",
    "Answer: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
    "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
    "\n",
    "Question: There were nine computers in the server room. Five more computers were installed each day, from\n",
    "monday to thursday. How many computers are now in the server room?\n",
    "Answer: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
    "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
    "The answer is 29.\n",
    "\n",
    "Question: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
    "golf balls did he have at the end of wednesday?\n",
    "Answer: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
    "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
    "\n",
    "\n",
    "Question: Olivia has 23 dollars, she bought 5 bagels for 3 each. \n",
    "How much money does she have left?\n",
    "Answer: \n",
    "\n",
    "\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9b1e7-b49d-4376-aca4-76b9fee8ba29",
   "metadata": {},
   "source": [
    "# Generated Knowledge Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f525eb89-f7d2-49ba-98ab-269e409942d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: The answer is yes.\n",
      "\n",
      "The knowledge states that \"Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game\". So part of golf is trying to get a higher point total than others.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"Question: Part of golf is trying to get a higher point total than others. Yes or No?\n",
    "\n",
    "Knowledge: The objective of golf is to play a set of holes in the least number of strokes. A round of golf typically consists of 18 holes. \n",
    "Each hole is played once in the round on a standard golf course. \n",
    "Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game.\n",
    "\n",
    "Explain and Answer:\n",
    "\n",
    "\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9fc965-70f4-4e7e-b9a6-f66299c9a868",
   "metadata": {},
   "source": [
    "# Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de7f3f35-371a-4039-a201-feaee77628ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: There is only one 'm' in the word 'Weather'.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"How many 'm's are in the word 'Weather'?\n",
    "\n",
    "\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4d50a8b-da53-4d9f-b6b2-a7b64e0bc310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: Yes, I am sure. The word 'Weather' has only one 'm'.\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    \"\"\"question: How many 'm's are in the word 'Weather'?\n",
    "your previous answer: There is only one 'm' in the word 'Weather'.\n",
    "question: Are you sure?\n",
    "answer:?\n",
    "\n",
    "\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01fa4e07-d977-43c1-aea2-0097c26d4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2"
     ]
    }
   ],
   "source": [
    "def generate():\n",
    "\n",
    "  model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "  responses = model.generate_content(\n",
    "    \"\"\"Read the Instruction below and provide an answer.\n",
    "\n",
    "### INSTRUCTION:\n",
    "How many 'm's are in the word 'Weather'?\"\"\",\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=True,\n",
    "  )\n",
    "  \n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03d46810-70e2-49b6-a917-d753bc077225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am sure. The word \"Weather\" has only one 'm'."
     ]
    }
   ],
   "source": [
    "def generate():\n",
    "\n",
    "  model = GenerativeModel(\"gemini-1.0-pro-001\")\n",
    "  responses = model.generate_content(\n",
    "    \"\"\"question: How many 'm's are in the word 'Weather'?\n",
    "your previous answer: There is only one 'm' in the word 'Weather'.\n",
    "question: Are you sure?\n",
    "answer?\"\"\",\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=True,\n",
    "  )\n",
    "  \n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9aa88979-a6be-4122-9c59-95f84727cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import CodeGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9d4b9d2-4ee4-46fc-bc3d-cc73c13b45e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Model: ```python\n",
      "import base64\n",
      "from PIL import Image\n",
      "\n",
      "# Open the image\n",
      "image = Image.open(\"image.jpg\")\n",
      "\n",
      "# Convert the image to a binary string\n",
      "binary_data = image.tobytes()\n",
      "\n",
      "# Encode the binary string in base64\n",
      "base64_data = base64.b64encode(binary_data)\n",
      "\n",
      "# Print the base64-encoded string\n",
      "print(base64_data)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"max_output_tokens\": 1024,\n",
    "    \"temperature\": 0.1\n",
    "}\n",
    "model = CodeGenerationModel.from_pretrained(\"code-bison\")\n",
    "response = model.predict(\n",
    "     \"\"\"Give me code in python to open an image and transform the binary in base64. You only can use python native libraries\"\"\",\n",
    "    **parameters\n",
    ")\n",
    "print(f\"Response from Model: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca5679-5332-4c55-a35c-348ebb5a7c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vertex)",
   "language": "python",
   "name": "vertex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
