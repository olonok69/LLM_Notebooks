{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0547887-3a02-4507-87c2-6fe8a65515c0",
   "metadata": {},
   "source": [
    "# RAG\n",
    "- RAG is a technique for augmenting LLM knowledge with additional data.\n",
    "- LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on.\n",
    "- If you want to build AI applications that can reason about private data or data introduced after a model's cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "- The process of bringing the appropriate information and inserting it into the model prompt is known as retrieval augmented generation (RAG).\n",
    "\n",
    "# Langchain\n",
    "LangChain is a framework for developing applications powered by large language models (LLMs).\n",
    "\n",
    "https://python.langchain.com/docs/introduction/\n",
    "\n",
    "# NIM\n",
    "NIM is a set of optimized cloud-native microservices designed to shorten time-to-market and simplify deployment of generative AI models anywhere, across cloud, data center, and GPU-accelerated workstations. It expands the developer pool by abstracting away the complexities of AI model development and packaging for production â€Œusing industry-standard APIs.\n",
    "\n",
    "https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/llm-apis\n",
    "\n",
    "![image.png](images/NIM.png)\n",
    "\n",
    " # NVIDIA API Catalog\n",
    " https://docs.api.nvidia.com/\n",
    " \n",
    "- NVIDIA API Catalog is a hosted platform for accessing a wide range of microservices online.\n",
    "- You can test models on the catalog and then export them with an NVIDIA AI Enterprise license for on-premises or cloud deployment\n",
    "  \n",
    "# Milvus vectorStore\n",
    "https://milvus.io/docs\n",
    "\n",
    "Milvus is a high-performance, highly scalable vector database that runs efficiently across a wide range of environments, from a laptop to large-scale distributed systems. It is available as both open-source software and a cloud service.\n",
    "\n",
    "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache 2.0 license. Most contributors are experts from the high-performance computing (HPC) community, specializing in building large-scale systems and optimizing hardware-aware code.\n",
    "\n",
    "# Mistral mixtral-8x7b-instruct\n",
    "\n",
    "https://docs.api.nvidia.com/nim/reference/mistralai-mixtral-8x7b-instruct\n",
    "\n",
    "\n",
    "Mixtral 8x7B Instruct is a language model that can follow instructions, complete requests, and generate creative text formats. Mixtral 8x7B a high-quality sparse mixture of experts model (SMoE) with open weights.\n",
    "\n",
    "This model has been optimized through supervised fine-tuning and direct preference optimization (DPO) for careful instruction following. On MT-Bench, it reaches a score of 8.30, making it the best open-source model, with a performance comparable to GPT3.5.\n",
    "\n",
    "Mixtral outperforms Llama 2 70B on most benchmarks with 6x faster inference. It is the strongest open-weight model with a permissive license and the best model overall regarding cost/performance trade-offs. In particular, it matches or outperforms GPT3.5 on most standard benchmarks.\n",
    "\n",
    "Mixtral has the following capabilities.\n",
    "\n",
    "- It gracefully handles a context of 32k tokens.\n",
    "- It handles English, French, Italian, German and Spanish.\n",
    "- It shows strong performance in code generation.\n",
    "- It can be finetuned into an instruction-following model that achieves a score of 8.3 on MT-Bench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157165d2-0e06-455d-96d5-60d96ddbfc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import os\n",
    "# read env file\n",
    "ROOT_DIR = os.getcwd()\n",
    "config = dotenv_values(os.path.join(ROOT_DIR, \"keys\", \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a7bc7-190d-4e38-bfd4-4f80bd9d28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NVIDIA_API_KEY'] = config.get('NVIDIA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796406bf-43e0-4896-ba9b-67aa2d37d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run and see that you can genreate a respond successfully\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA,NVIDIAEmbeddings\n",
    "llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", max_tokens=1024)\n",
    "embedder_document = NVIDIAEmbeddings(model=\"NV-Embed-QA\", truncate=\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849642b-6e10-4a44-8f03-714ba32945d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "urls_content = []\n",
    "\n",
    "url_template1 = \"https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-{quarter}-quarter-fiscal-{year}\"\n",
    "url_template2 = \"https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-{quarter}-quarter-and-fiscal-{year}\"\n",
    "\n",
    "for quarter in [\"first\", \"second\", \"third\", \"fourth\"]:\n",
    "    for year in range(2020,2025):\n",
    "        args = {\"quarter\":quarter, \"year\": str(year)}\n",
    "        if quarter == \"fourth\":\n",
    "            urls_content.append(requests.get(url_template2.format(**args)).content)\n",
    "        else:\n",
    "            urls_content.append(requests.get(url_template1.format(**args)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef77d6-a3dc-4955-a8b0-de121100c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the url, title, text content, and tables in the html\n",
    "from bs4 import BeautifulSoup\n",
    "import markdownify\n",
    "\n",
    "def extract_url_title_time(soup):\n",
    "    url = \"\"\n",
    "    title = \"\"\n",
    "    revised_time = \"\"\n",
    "    tables = []\n",
    "    try:\n",
    "        if soup.find(\"title\"):\n",
    "            title = str(soup.find(\"title\").string)\n",
    "\n",
    "        og_url_meta = soup.find(\"meta\", property=\"og:url\")\n",
    "        if og_url_meta:\n",
    "            url = og_url_meta.get(\"content\", \"\")\n",
    "\n",
    "        for table in soup.find_all(\"table\"):\n",
    "            tables.append(markdownify.markdownify(str(table)))\n",
    "            table.decompose()\n",
    "\n",
    "        text_content = soup.get_text(separator=' ', strip=True)\n",
    "        text_content = ' '.join(text_content.split())\n",
    "\n",
    "        return url, title,text_content, tables\n",
    "    except:\n",
    "        print(\"parse error\")\n",
    "        return \"\", \"\", \"\", \"\", []\n",
    "\n",
    "parsed_htmls = []\n",
    "for url_content in urls_content:\n",
    "    soup = BeautifulSoup(url_content, 'html.parser')\n",
    "    url, title, content, tables = extract_url_title_time(soup)\n",
    "    parsed_htmls.append({\"url\":url, \"title\":title, \"content\":content, \"tables\":tables})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56972d19-ddb0-4c13-baf9-55651ffb8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_htmls[0][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db559e-fe64-47d6-93d4-14f9f53d3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_htmls[0][\"tables\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47ba57-17d9-4f35-8ba5-77e7c176a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize tables\n",
    "def get_table_summary(table, title, llm):\n",
    "    res = \"\"\n",
    "    try:\n",
    "        #table = markdownify.markdownify(table)\n",
    "        prompt = f\"\"\"\n",
    "                    [INST] You are a virtual assistant.  Your task is to understand the content of TABLE in the markdown format.\n",
    "                    TABLE is from \"{title}\".  Summarize the information in TABLE into SUMMARY. SUMMARY MUST be concise. Return SUMMARY only and nothing else.\n",
    "                    TABLE: ```{table}```\n",
    "                    Summary:\n",
    "                    [/INST]\n",
    "                \"\"\"\n",
    "        result = llm.invoke(prompt)\n",
    "        res = result.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} while getting table summary from LLM\")\n",
    "        if not os.getenv(\"NVIDIA_API_KEY\", False):\n",
    "            print(\"NVIDIA_API_KEY not set\")\n",
    "        pass\n",
    "    finally:\n",
    "        return res\n",
    "\n",
    "\n",
    "for parsed_item in parsed_htmls:\n",
    "    title = parsed_item['title']\n",
    "    for idx, table in enumerate(parsed_item['tables']):\n",
    "        print(f\"parsing tables in {title}...\")\n",
    "        table = get_table_summary(table, title, llm)\n",
    "        parsed_item['tables'][idx] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05174198-1422-40b1-9522-1e9f83342d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad003da3-617d-4275-8756-99ddbdfc9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parsed_htmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb728b-e92d-48d7-9d32-3ccda7f66351",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_htmls[0]['tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575c1cc-6cc6-49ff-8505-99fbcd32f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_item['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf24ac5-e6e9-4a36-8803-7482de080fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_item['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15055ce9-36ce-4087-a6c4-712dac77ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsed_item['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e03254-1af6-40f5-a484-109825dceba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_item['tables'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d926682-f0cd-4538-875e-8327a198f91e",
   "metadata": {},
   "source": [
    "# Splitter Model\n",
    "- https://huggingface.co/intfloat/e5-large-v2\n",
    "- https://api.python.langchain.com/en/latest/sentence_transformers/langchain_text_splitters.sentence_transformers.SentenceTransformersTokenTextSplitter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa832f02-dc73-4631-a915-367078b7c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "TEXT_SPLITTER_MODEL = \"intfloat/e5-large-v2\"\n",
    "TEXT_SPLITTER_CHUNCK_SIZE = 200\n",
    "TEXT_SPLITTER_CHUNCK_OVERLAP = 50\n",
    "\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    model_name=TEXT_SPLITTER_MODEL,\n",
    "    tokens_per_chunk=TEXT_SPLITTER_CHUNCK_SIZE,\n",
    "    chunk_overlap=TEXT_SPLITTER_CHUNCK_OVERLAP,\n",
    ")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for parsed_item in parsed_htmls:\n",
    "    title = parsed_item['title']\n",
    "    url =  parsed_item['url']\n",
    "    text_content = parsed_item['content']\n",
    "    documents.append(Document(page_content=text_content, metadata = {'title':title, 'url':url}))\n",
    "\n",
    "    for idx, table in enumerate(parsed_item['tables']):\n",
    "        table_content = table\n",
    "        documents.append(Document(page_content=table, metadata = {'title':title, 'url':url}))\n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(f\"obtain {len(documents)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf405d3-699c-4af2-92ab-49b1b8aa3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cf8c8-882f-4659-a64a-3c4438913182",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"./milvus_example.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ad78a-63a3-4e33-b8d8-a0bca4ee338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"NVIDIA_Finance\"\n",
    "from langchain_milvus import Milvus\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents,\n",
    "    embedder_document,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_args={\"uri\": URI}, # replace this with the ip of the workstation where milvus is running\n",
    "    drop_old=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b5995-55d1-40bc-aa3f-235300bf06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search_with_score(\"what are 2024 Q3 revenues? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e9890-3670-4f32-8527-1ffd9f6e8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11755811-5a26-4591-8c13-0ecf1cb175ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"[INST]You are a friendly virtual assistant and maintain a conversational, polite, patient, friendly and gender neutral tone throughout the conversation.\n",
    "\n",
    "Your task is to understand the QUESTION, read the Content list from the DOCUMENT delimited by ```, generate an answer based on the Content, and provide references used in answering the question in the format \"[Title](URL)\".\n",
    "Do not depend on outside knowledge or fabricate responses.\n",
    "DOCUMENT: ```{context}```\n",
    "\n",
    "Your response should follow these steps:\n",
    "\n",
    "1. The answer should be short and concise, clear.\n",
    "    * If detailed instructions are required, present them in an ordered list or bullet points.\n",
    "2. If the answer to the question is not available in the provided DOCUMENT, ONLY respond that you couldn't find any information related to the QUESTION, and do not show references and citations.\n",
    "3. Citation\n",
    "    * ALWAYS start the citation section with \"Here are the sources to generate response.\" and follow with references in markdown link format [Title](URL) to support the answer.\n",
    "    * Use Bullets to display the reference [Title](URL).\n",
    "    * You MUST ONLY use the URL extracted from the DOCUMENT as the reference link. DO NOT fabricate or use any link outside the DOCUMENT as reference.\n",
    "    * Avoid over-citation. Only include references that were directly used in generating the response.\n",
    "    * If no reference URL can be provided, remove the entire citation section.\n",
    "    * The Citation section can include one or more references. DO NOT include same URL as multiple references. ALWAYS append the citation section at the end of your response.\n",
    "    * You MUST follow the below format as an example for this citation section:\n",
    "      Here are the sources used to generate this response:\n",
    "      * [Title](URL)\n",
    "[/INST]\n",
    "[INST]\n",
    "QUESTION: {question}\n",
    "FINAL ANSWER:[/INST]\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e39c9-bf18-49a9-bd4e-948e6a5d5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(chunks):\n",
    "    context = \"\"\n",
    "    for chunk in chunks:\n",
    "        context = context + \"\\n  Content: \" + chunk.page_content + \" | Title: (\" + chunk.metadata[\"title\"] + \") | URL: (\" + chunk.metadata.get(\"url\", \"source\") + \")\"\n",
    "    return context\n",
    "\n",
    "\n",
    "def generate_answer(llm, vectorstore, prompt_template, question):\n",
    "    retrieved_chunks = vectorstore.similarity_search(question)\n",
    "    context = build_context(retrieved_chunks)\n",
    "    args = {\"context\":context, \"question\":question}\n",
    "    prompt = prompt_template.format(**args)\n",
    "    ans = llm.invoke(prompt)\n",
    "    return ans.content\n",
    "\n",
    "\n",
    "question = \"what are 2024 Q1 revenues?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc708ed-39b0-485a-9ffb-cab40a39070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answer(llm, vectorstore, prompt_template, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf0bb6-81c9-468b-9a67-437146b96c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
