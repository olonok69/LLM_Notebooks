{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/microsoft/Phi3_128k_gguf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKCjFAOi6kqV"
      },
      "source": [
        "# Phi3\n",
        "https://github.com/microsoft/Phi-3CookBook\n",
        "\n",
        "https://huggingface.co/professorf/phi-3-mini-128k-f16-gguf\n",
        "\n",
        "\n",
        "# Llama.cpp\n",
        "enable LLM inference with minimal setup and state-of-the-art performance on a wide variety of hardware - locally and in the cloud\n",
        "\n",
        "https://github.com/ggerganov/llama.cpp\n",
        "\n",
        "# gguf\n",
        "GGUF is a file format for storing models for inference with GGML and executors based on GGML. GGUF is a binary format that is designed for fast loading and saving of models, and for ease of reading. Models are traditionally developed using PyTorch or another framework, and then converted to GGUF for use in GGML.\n",
        "\n",
        "https://huggingface.co/docs/hub/gguf\n",
        "\n",
        "## Install\n",
        "pip3 install huggingface-hub hf_transfer\n",
        "\n",
        "huggingface-cli download professorf/phi-3-mini-128k-f16-gguf phi-3-mini-128k-f16.gguf --local-dir /content/drive/MyDrive/models/phi3 --local-dir-use-symlinks False\n",
        "\n",
        "\n",
        "CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYc50Wqjr1uN",
        "outputId": "54b1cd39-a1dd-4635-bbdf-5cb204714a50"
      },
      "outputs": [],
      "source": [
        "!pip3 install huggingface-hub hf_transfer --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKyPyZtAsQEY",
        "outputId": "717087fb-d0fc-41bd-d333-04844cdcfaac"
      },
      "outputs": [],
      "source": [
        "! huggingface-cli download professorf/phi-3-mini-128k-f16-gguf phi-3-mini-128k-f16.gguf --local-dir /content/drive/MyDrive/models/gguf/phi3 --local-dir-use-symlinks False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4fdJgr-88OB",
        "outputId": "5d32ea97-a62d-45b4-c70d-c4d1b1cf6d2f"
      },
      "outputs": [],
      "source": [
        "%pip install flash_attn einops timm mlflow pyngrok accelerate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsenULj6tbxY",
        "outputId": "bd1f8f21-f996-446a-d3fe-41ace159d33e"
      },
      "outputs": [],
      "source": [
        "! export CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\"\n",
        "! export FORCE_CMAKE=1\n",
        "! pip install llama-cpp-python --force-reinstall \\\n",
        "  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzSLKMTBb5tG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "#del llm\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrinoLSuu0Pj",
        "outputId": "fad2fd3d-13e0-47bb-93a0-340fab17627c"
      },
      "outputs": [],
      "source": [
        "from llama_cpp import Llama\n",
        "llm = Llama(\n",
        "  model_path=\"/content/drive/MyDrive/models/home_made/phi-3-mini-128k-instruct_q8_0.gguf\",  # Download the model file first\n",
        "  n_ctx=2048,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
        "  n_threads=8,            # The number of CPU threads to use, tailor to your system and the resulting performance\n",
        "  n_gpu_layers=-1,         # The number of layers to offload to GPU, if you have GPU acceleration available\n",
        "  verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdZMkEIlXFER"
      },
      "outputs": [],
      "source": [
        "llm.verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_642CS7vJQN"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Crossrail link 'to get go-ahead' The £10bn Crossrail transport plan, backed by business groups, is to get the go-ahead this month, according to The Mail on Sunday.\n",
        "It says the UK Treasury has allocated £7.5bn ($13.99bn) for the project and that talks with business groups on raising the rest will begin shortly.\n",
        "The much delayed Crossrail Link Bill would provide for a fast cross-London rail link. The paper says it will go before the House of Commons on 23 February.\n",
        "A second reading could follow on 16 or 17 March. We've always said we are going to introduce a hybrid Bill for Crossrail in the Spring and this remains the case,\n",
        "the Department for Transport said on Sunday. Jeremy de Souza, a spokesman for Crossrail, said on Sunday he could not confirm whether the Treasury was planning to invest £7.5bn\n",
        "or when the bill would go before Parliament. However, he said some impetus may have been provided by the proximity of an election.\n",
        "The new line would go out as far as Maidenhead, Berkshire, to the west of London, and link Heathrow to Canary Wharf via the City.\n",
        "Heathrow to the City would take 40 minutes, dramatically cutting journey times for business travellers, and reducing overcrowding on the tube.\n",
        "The line has the support of the Mayor of London, Ken Livingstone, business groups and the government, but there have been three years of arguments over how it should be funded.\n",
        "The Mail on Sunday's Financial Mail said the £7.5bn of Treasury money was earmarked for spending in £2.5bn instalments in 2010, 2011 and 2012.\"\"\"\n",
        "\n",
        "text2 = \"\"\"           Celeste Barrios-Cruz\n",
        "(312) 208-6505 | Celestebarrios35@gmail.com | LinkedIn | GitHub | Chicago, IL\n",
        "\n",
        "PROFESSIONAL SUMMARY\n",
        "●\n",
        "Innovative thinker with extensive knowledge of SQL, experience utilizing Python, object oriented\n",
        "programming: C++, front end knowledge of JavaScript\n",
        "●\n",
        "Excellent communication skills (English and Spanish) including teamwork and collaboration\n",
        "●\n",
        "Outstanding organization ability including problem-solving, and time management skills.\n",
        "\n",
        "SKILLS\n",
        "Programming Language: Python, C++, JavaScript, HTML5, CSS3, TypeScript\n",
        "Web Technologies/Development Frameworks: NumPy, Pandas, MATLAB, Flask, jQuery, AJAX, JASON,\n",
        "BootstrapUI, Angular7.0\n",
        "Database: SQL, PostgreSQL, SQLite\n",
        "Software: Microsoft Office (Word, Excel, PowerPoint), Google Developer Tools\n",
        "Tools/Methodologies: Data Structures, Algorithms, GitHub, GIT, Heroku, Scrum, Agile Methodology, Agile\n",
        "Software Development, Project Management, Anaconda, Jupyter Notebook, Visual Studio, Software Development,\n",
        "Data Modeler, Tableau\n",
        "Languages: Spanish (fluent conversational skills)\n",
        "\n",
        "EDUCATION\n",
        "University of Illinois at Chicago (UIC), Chicago, IL\n",
        "Bachelor of Science in Math & Computer Science                                               December 2019\n",
        "\n",
        "PROFESSIONAL EXPERIENCE\n",
        "Empower Saturday School, Chicago IL\n",
        "\n",
        "\n",
        "Co-Director of Technology\n",
        "\n",
        "          November 2020-Present\n",
        "●\n",
        "Volunteer in a Non-Profit foundation to provide tutoring for underprivileged youth in Chicago implementing\n",
        "WordPress for a student portal and website with upcoming donation features built-in.\n",
        "\n",
        "Coding Temple, Chicago IL\n",
        "Software Engineer                                                                                               May 2020-July 2020\n",
        "●\n",
        "Participated in intensive professional development experience in code production.\n",
        "●\n",
        "Collaborated with a team to utilize Flask to revamp a law firm’s website from a previous HTML/CSS draft\n",
        "and then deployed the new website on Heroku from GitHub.\n",
        "●\n",
        "Created an Entity Relationship Diagram (ERD) using lucidchart.com to create a database; also used SQL\n",
        "to export and import data between different data sources.\n",
        "●\n",
        "Utilized Object-Oriented Programming (OOP) concepts with Python to create a parking garage system.\n",
        "●\n",
        "Oversaw Full Web UI Development on 5+ projects using Angular 4 and above, AngularJS, JavaScript,\n",
        "HTML, CSS, third party Angular frameworks, JQuery and JSON.\n",
        "●\n",
        "Used 5+ Python libraries and SQL queries/subqueries to create several datasets which produced statistics,\n",
        "tables, figures, charts and graphs.\n",
        "●\n",
        "Completed case study problem sets using Python, NumPy, SciPy, Pandas packages in order to enhance\n",
        "understanding of the functionality of each program and how to get concrete results.\n",
        "\n",
        "PROJECTS\n",
        "Avengers Phone Book\n",
        "\n",
        "\n",
        "●\n",
        "Created phone numbers for Avengers Phone Book using Flask and displayed them to your front page.\n",
        "●\n",
        "Designed a project so that characters could create,read, update their phone number from the phone book;\n",
        "the project is hosted on Heroku.\n",
        "Good Send\n",
        "\n",
        "\n",
        "\n",
        "●\n",
        "Collaborated with 2+ developers to design both administrator and client web portals using Python, Flask,\n",
        "SQLite and multiple APIs; Utilized Github for version control and deployed the final product on Heroku.\n",
        "●\n",
        "Individually designed and deployed a SQLite database to allow organization to run a more secure,\n",
        "organized, automated and efficient operation resulting in higher client satisfaction.\n",
        "●\n",
        "Incorporated Flask-Admin and Flask-Login to allow the administrator to view, create, update and delete.\n",
        "MyMoviePoster\n",
        "\n",
        "●\n",
        "Linked Spotify playlist to movie poster using an API.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "classes = [\"cv\", \"non-cv\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QTqBZn_vKnO"
      },
      "outputs": [],
      "source": [
        "prompt_1 =  f\"\"\"you are an expert document classifier\n",
        "Classify the following text using these {len(classes)} classes: {classes}\n",
        "Only use the labels provided: {classes}\n",
        "\n",
        "Confidence score: float of 0-1.\n",
        "for example:\n",
        "0 means you are completely sure that the document does not belongs to class x\n",
        "1 means you are completely sure that the document belong to class x\n",
        "output: only respond with a json with these 2 attrubutes 'label' = class predicted, 'score': float\n",
        "\n",
        "#begin text\n",
        "{text2}.\n",
        "#end text\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pnozF1cw5E-"
      },
      "outputs": [],
      "source": [
        "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'\n",
        "\n",
        "prompt = f'{chat_template.format(input=prompt_1)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqmP3di0w-B9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSx0ZK9tvVTO",
        "outputId": "2e9f87bc-b178-482f-d13c-acf9c503efa0"
      },
      "outputs": [],
      "source": [
        "time1=  datetime.datetime.now()\n",
        "# Simple inference example\n",
        "output = llm(\n",
        "  f\"{prompt}\", # Prompt\n",
        "  temperature = 0.7, # Controls randomness in output\n",
        "  max_tokens=2048,  # Generate up to 512 tokens\n",
        "  stop=[\"</s>\"],   # Example stop token - not necessarily correct for this specific model! Please check before using.\n",
        "  echo=False        # Whether to echo the prompt\n",
        ")\n",
        "time2=  datetime.datetime.now()\n",
        "print(time2-time1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db-ulJnpvcOO",
        "outputId": "9408c660-3934-45b4-91aa-ea0a1d9a563c"
      },
      "outputs": [],
      "source": [
        "output['choices'][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JGEXWcwXvwuN",
        "outputId": "d3193a22-3666-4eb1-d767-6c7a7b6b294d"
      },
      "outputs": [],
      "source": [
        "output['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEE1dutwxlws"
      },
      "outputs": [],
      "source": [
        "prompt2 =  f\"\"\"you are an expert document classifier\n",
        "Classify the following text using these {len(classes)} classes: {classes}\n",
        "Only use the labels provided: {classes}\n",
        "\n",
        "Confidence score: float of 0-1.\n",
        "for example:\n",
        "0 means you are completely sure that the document does not belongs to class x\n",
        "1 means you are completely sure that the document belong to class x\n",
        "output: only respond with a json with these 2 attrubutes 'label' = class predicted, 'score': float\n",
        "\n",
        "#begin text\n",
        "{text}.\n",
        "#end text\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZnnjdPBxoxG"
      },
      "outputs": [],
      "source": [
        "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'\n",
        "\n",
        "prompt = f'{chat_template.format(input=prompt2)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwVVxkwzxrOU",
        "outputId": "9d9e76d5-92aa-4b08-dce3-a9ecf4b21413"
      },
      "outputs": [],
      "source": [
        "time1=  datetime.datetime.now()\n",
        "# Simple inference example\n",
        "output = llm(\n",
        "  f\"{prompt}\", # Prompt\n",
        "  temperature = 0.7, # Controls randomness in output\n",
        "  max_tokens=2048,  # Generate up to 512 tokens\n",
        "  stop=[\"</s>\"],   # Example stop token - not necessarily correct for this specific model! Please check before using.\n",
        "  echo=False        # Whether to echo the prompt\n",
        ")\n",
        "time2=  datetime.datetime.now()\n",
        "print(time2-time1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6ykm5OSdxwx8",
        "outputId": "b83a9e88-2d1d-4612-94a6-e7eb7cb542c3"
      },
      "outputs": [],
      "source": [
        "output['choices'][0]['text']"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNJF3J/lGueZrBsnaI3QD7h",
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/olonok69/LLM_Notebooks/blob/main/microsoft/Phi3_128k_gguf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
