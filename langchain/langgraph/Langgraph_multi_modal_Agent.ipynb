{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/langchain/langgraph/Langgraph_multi_modal_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqLiHdEPfYS9"
      },
      "source": [
        "# Langgraph multi modal Agent\n",
        "\n",
        "### Tools\n",
        "Tools are external resources, services, or APIs that an LLM agent can access and utilize to expand its capabilities and perform specific tasks. These supplementary components allow the agent to go beyond its core language processing abilities, enabling it to interact with external systems, retrieve information, or execute actions that would otherwise be outside its scope. By integrating tools, LLM agents can provide more comprehensive and practical solutions to user queries and commands.\n",
        "\n",
        "A tool consists of:\n",
        "\n",
        "- The name of the tool.\n",
        "- A description of what the tool does.\n",
        "- A JSON schema defining the inputs to the tool.\n",
        "- A function (and, optionally, an async variant of the function)\n",
        "\n",
        "When a tool is bound to a model, the name, description and JSON schema are provided as context to the model. Given a list of tools and a set of instructions, a model can request to call one or more tools with specific inputs.\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/concepts/#tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1zgYofee0V0"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_anthropic langchain_openai langchain-google-genai langchain-community  langchain-chroma  pandas  ipywidgets pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NnIKUyvf53I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"lg-multimodal-agent\"\n",
        "os.environ[\"OPENAI_API_KEY\"] =  userdata.get(\"KEY_OPENAI\")\n",
        "os.environ[\"ANTHROPIC_API_KEY\"]=  userdata.get(\"ANTROPIC_KEY\")\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ugM07ugSnt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "def read_travel_data(file_path: str = \"/content/drive/MyDrive/data/synthetic_travel_data.csv\") -> pd.DataFrame:\n",
        "    \"\"\"Read travel data from CSV file\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        return pd.DataFrame(\n",
        "            columns=[\n",
        "                \"Name\",\n",
        "                \"Current_Location\",\n",
        "                \"Age\",\n",
        "                \"Past_Travel_Destinations\",\n",
        "                \"Number_of_Trips\",\n",
        "                \"Flight_Number\",\n",
        "                \"Departure_City\",\n",
        "                \"Arrival_City\",\n",
        "                \"Flight_Date\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "@tool\n",
        "def compare_and_recommend_destination(name: str) -> str:\n",
        "    \"\"\"This tool is used to check which destinations user has already traveled.\n",
        "    Use name of the user to fetch the information about that user.\n",
        "    If user has already been to a city then do not recommend that city.\n",
        "\n",
        "    Args:\n",
        "        name (str): Name of the user.\n",
        "    Returns:\n",
        "        str: Destination to be recommended.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df = read_travel_data()\n",
        "\n",
        "    if name not in df[\"Name\"].values:\n",
        "        return \"User not found in the travel database.\"\n",
        "\n",
        "    user_data = df[df[\"Name\"] == name].iloc[0]\n",
        "    current_location = user_data[\"Current_Location\"]\n",
        "    age = user_data[\"Age\"]\n",
        "    past_destinations = user_data[\"Past_Travel_Destinations\"].split(\", \")\n",
        "\n",
        "    # Get all past destinations of users with similar age (Â±5 years) and same current location\n",
        "    similar_users = df[\n",
        "        (df[\"Current_Location\"] == current_location)\n",
        "        & (df[\"Age\"].between(age - 5, age + 5))\n",
        "    ]\n",
        "    all_destinations = [\n",
        "        dest\n",
        "        for user_dests in similar_users[\"Past_Travel_Destinations\"].str.split(\", \")\n",
        "        for dest in user_dests\n",
        "    ]\n",
        "\n",
        "    # Count occurrences of each destination\n",
        "    destination_counts = Counter(all_destinations)\n",
        "\n",
        "    # Remove user's current location and past destinations from recommendations\n",
        "    for dest in [current_location] + past_destinations:\n",
        "        if dest in destination_counts:\n",
        "            del destination_counts[dest]\n",
        "\n",
        "    if not destination_counts:\n",
        "        return f\"No new recommendations found for users in {current_location} with similar age.\"\n",
        "\n",
        "    # Get the most common destination\n",
        "    recommended_destination = destination_counts.most_common(1)[0][0]\n",
        "\n",
        "    return f\"Based on your current location ({current_location}), age ({age}), and past travel data, we recommend visiting {recommended_destination}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KdgJ5V6-pyqc",
        "outputId": "1623ad75-6cdb-49ca-ac46-d92d582d8d33"
      },
      "outputs": [],
      "source": [
        "df = read_travel_data()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "vWj6djXZqHUD",
        "outputId": "4a6bbafc-91cc-4b76-a953-7520e0a08a46"
      },
      "outputs": [],
      "source": [
        "df[df.Name==\"Christian Morales\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "vRG98zQ06AiR",
        "outputId": "6740c9db-57e9-492b-dfc8-6e7f48334d98"
      },
      "outputs": [],
      "source": [
        "df[df['Current_Location']== \"Venice\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XU6nYAS7ytNL",
        "outputId": "53604717-f077-4d26-9ac5-dad56faeeb68"
      },
      "outputs": [],
      "source": [
        "compare_and_recommend_destination(\"Kevin Garcia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDypRM59giaW"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Set up the model\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md7-JcWQgcYX"
      },
      "outputs": [],
      "source": [
        "tools = [compare_and_recommend_destination]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ud81auOiraT"
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7bSUtkUiuOa"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langgraph.prebuilt import ToolInvocation\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7xSi-T7iuLP",
        "outputId": "59171aa3-b536-488f-cadd-5bf621eb00f3"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, MessagesState, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "    \"\"\"Always use tools to fulfill user requests.\n",
        "    1. If you do not have enough inputs to execute a tool then you can ask for more information.\n",
        "    2. If user has uploaded image and 'image_processing_node' has returned city and activity then use that information to call 'chatbot'\n",
        "    \"\"\"\n",
        "    # Filter out messages with image type\n",
        "    # text_messages = [msg for msg in state[\"messages\"] if msg['content'][0].get(\"type\") != \"image\"]\n",
        "    text_messages = [\n",
        "        msg for msg in state[\"messages\"]\n",
        "        if not (isinstance(msg.content, list) and msg.content[0].get(\"type\") == \"image_url\")\n",
        "    ]\n",
        "\n",
        "    # Invoke LLM with only text messages\n",
        "    return {\"messages\": [llm_with_tools.invoke(text_messages)]}\n",
        "\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt-Uk3fuiuJo",
        "outputId": "0571514e-b064-477b-ca18-058d9d89cf23"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "tool_node = ToolNode(tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    tools_condition,\n",
        "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFEfp5S2jSvn"
      },
      "outputs": [],
      "source": [
        "def process_image_input(state):\n",
        "    \"\"\"\n",
        "    Process image input. This tool will return activity shown in this image.\n",
        "    \"\"\"\n",
        "    last_message = state[\"messages\"][-1].content[0]\n",
        "    input_image = last_message['image_url']['url']\n",
        "    print(input_image)\n",
        "    message = HumanMessage(\n",
        "        content=[\n",
        "            {\"type\": \"text\", \"text\": \"Which activity is shown in this image?\"},\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                # \"image_url\": {\"url\": {input_image}},\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{input_image}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "    response = llm.invoke([message])\n",
        "    print(response.content)\n",
        "    output = {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=f\"Image information: {response.content}\", name=\"image_description\"\n",
        "            )\n",
        "        ],\n",
        "    }\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6XUpVyEjetg",
        "outputId": "d137387a-43e7-43f6-88d0-1e14ac9a8052"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_node(\"image_processing_node\", process_image_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ky7QuA1jht7"
      },
      "outputs": [],
      "source": [
        "def is_image_node(state):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if hasattr(last_message, \"content\") and isinstance(last_message.content, list):\n",
        "        for item in last_message.content:\n",
        "            if isinstance(item, dict) and item.get(\"type\") == \"image_url\":\n",
        "                return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "i3k1F2G3jksO",
        "outputId": "03b98ec3-27eb-4cdb-be8b-4d1325111230"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from IPython.display import Image, display\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Any time a tool is called, we return to the chatbot to decide the next step\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "graph_builder.add_edge(\"image_processing_node\", \"chatbot\")\n",
        "graph_builder.add_conditional_edges(START, is_image_node, {True: \"image_processing_node\", False:\"chatbot\"})\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDdYyXxZjtZc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Ot9RIFNckCtR",
        "outputId": "894e356c-2621-4a67-ae3f-4915f81e3375"
      },
      "outputs": [],
      "source": [
        "img = Image.open(\"/content/drive/MyDrive/data/images/images/zermatt.jpg\")\n",
        "img.resize((256, 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB1p7C7knN2R"
      },
      "outputs": [],
      "source": [
        "buffered = io.BytesIO()\n",
        "img.save(buffered, format=img.format)\n",
        "img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_1S88_3kvzi",
        "outputId": "847bc911-0c3a-478b-e90d-6818dcd9c20a"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "import pprint\n",
        "config = {\"configurable\": {\"thread_id\": \"20\"}}\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": img_str},\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "pprint.pprint(graph.invoke({\"messages\": message}, config)[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNTcoxcwn-Iu",
        "outputId": "d6666840-9c6a-4d39-efb4-1e4442c79568"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(\n",
        "    graph.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                (\n",
        "                    \"user\",\n",
        "                    \"My name is Kevin Garcia\",\n",
        "                )\n",
        "            ]\n",
        "        },\n",
        "        config,\n",
        "    )[\"messages\"][-1].content\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZh-60zD9Pkb",
        "outputId": "5f363d03-1b6e-4257-8570-3eb613af9703"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(\n",
        "    graph.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                (\n",
        "                    \"user\",\n",
        "                    \"yes I want some suggestions based on the picture\",\n",
        "                )\n",
        "            ]\n",
        "        },\n",
        "        config,\n",
        "    )[\"messages\"][-1].content\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBBtqG1s-xQd",
        "outputId": "d743d653-8b0d-4738-8f24-ec33c0e0ef12"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(\n",
        "    graph.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                (\n",
        "                    \"user\",\n",
        "                    \"yes I want only destinations in Europe \",\n",
        "                )\n",
        "            ]\n",
        "        },\n",
        "        config,\n",
        "    )[\"messages\"][-1].content\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOT9aBVUzU4Rgq4i9lum5Am",
      "include_colab_link": true,
      "mount_file_id": "1qYBiG8jPoqqvXaGMBBYNgeFfybz8DT70",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
