{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/langchain/custom/LangChain_Custom_LLMChat_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmHF-Axc4S5l"
      },
      "source": [
        "# Langchain Custom Models\n",
        "\n",
        "- https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html\n",
        "\n",
        "\n",
        "- https://python.langchain.com/docs/how_to/custom_chat_model/\n",
        "\n",
        "# Models\n",
        "- https://huggingface.co/microsoft/Phi-3.5-vision-instruct\n",
        "- https://github.com/microsoft/Phi-3CookBook\n",
        "\n",
        "- https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/tree/main\n",
        "- https://github.com/QwenLM/Qwen2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpI3WcUWP_G2",
        "outputId": "911af7f7-f01b-47e1-bf07-0c91e8b9548a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCtMoIW7QABt"
      },
      "source": [
        "# Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEGmUEJmPGVG",
        "outputId": "35c02067-5dd0-45da-e6e1-b9d6a7e6a96f"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow   optimum --quiet\n",
        "! pip install  evaluate  textstat tiktoken -q\n",
        "! pip install psutil pynvml -q\n",
        "! pip install -q   bitsandbytes sentencepiece\n",
        "! pip install datasets evaluate rouge_score -q\n",
        "! pip install transformers==4.46.3 -q\n",
        "! pip install accelerate -U -q\n",
        "! pip install langchain  langchain-community -q\n",
        "! pip install flash-attn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMhhKV5vQhK2"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, List, Optional\n",
        "from langchain_core.language_models import BaseChatModel\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatResult, ChatGeneration\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain_core.callbacks.manager import AsyncCallbackManagerForLLMRun\n",
        "from langchain_core.runnables import run_in_executor\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "class CustomLLMChat(BaseChatModel):\n",
        "    model_name: str = \"microsoft/Phi-3.5-vision-instruct\"\n",
        "    processor: AutoProcessor = None\n",
        "    model: AutoModelForCausalLM = None\n",
        "    model_path: str = None\n",
        "\n",
        "    def __init__(self, model_path, **kwargs: Any) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "        if model_path is not None:\n",
        "            self.model_name = model_path\n",
        "\n",
        "        self.processor = AutoProcessor.from_pretrained(self.model_name, trust_remote_code=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_name, trust_remote_code=True, torch_dtype=\"auto\", device_map=\"cuda:0\"\n",
        "        )\n",
        "\n",
        "    def _call(\n",
        "            self,\n",
        "            prompt: str,\n",
        "            image_path: Optional[str] = None,\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> str:\n",
        "        # Load and preprocess the image\n",
        "        image = Image.open(image_path) if image_path else None\n",
        "        inputs = self.processor(prompt, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "        # Generate response\n",
        "        generate_ids = self.model.generate(\n",
        "            **inputs, max_new_tokens=1000, eos_token_id=self.processor.tokenizer.eos_token_id\n",
        "        )\n",
        "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
        "        response = self.processor.batch_decode(generate_ids,\n",
        "                                               skip_special_tokens=True,\n",
        "                                               clean_up_tokenization_spaces=False)[0]\n",
        "        return response\n",
        "\n",
        "    async def _acall(\n",
        "            self,\n",
        "            prompt: str,\n",
        "            image_path: str,\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> str:\n",
        "        # Implement the async logic to generate a response from the model\n",
        "        return await run_in_executor(\n",
        "            None,\n",
        "            self._call,\n",
        "            prompt,\n",
        "            image_path,\n",
        "            stop,\n",
        "            run_manager.get_sync() if run_manager else None,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom-llm-vision-chat\"\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Dict[str, Any]:\n",
        "        return {\"model_name\": self.model_name}\n",
        "\n",
        "    def _generate(\n",
        "            self,\n",
        "            messages: List[BaseMessage],\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> ChatResult:\n",
        "        # Assumes the first message contains the prompt and the image path is in metadata\n",
        "        prompt = messages[0].content\n",
        "        try:\n",
        "            image_path = messages[0].metadata.get(\"image_path\")\n",
        "        except AttributeError:\n",
        "            image_path = None\n",
        "        response_text = self._call(prompt, image_path, stop, run_manager, **kwargs)\n",
        "\n",
        "        # Create AIMessage with the response\n",
        "        ai_message = AIMessage(content=response_text)\n",
        "        return ChatResult(generations=[ChatGeneration(message=ai_message)])\n",
        "\n",
        "\n",
        "def create_prompt(message: str, image_path: Optional[str] = None) -> List[BaseMessage]:\n",
        "    user_prompt = '<|user|>\\n'\n",
        "    assistant_prompt = '<|assistant|>\\n'\n",
        "    prompt_suffix = \"<|end|>\\n\"\n",
        "    img_token = \"<|image_1|>\\n\" if image_path else \"\"\n",
        "    prompt = f\"{user_prompt}{img_token}{message}{prompt_suffix}{assistant_prompt}\"\n",
        "\n",
        "    return [HumanMessage(content=prompt, metadata={\"image_path\": image_path})]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS0vCaDO03aD"
      },
      "outputs": [],
      "source": [
        "model_path =\"/content/drive/MyDrive/MODELS/Phi-3.5-vision-instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81lGVcT7Xrrr",
        "outputId": "4f858db4-bdec-4b55-af69-7906d5c1685b"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4-fyLgmTG0Z"
      },
      "outputs": [],
      "source": [
        "prompt = create_prompt(\"Describe this image\", '/content/drive/MyDrive/Google AI Studio/forest.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "UX7C00LBYIXh",
        "outputId": "1bf64a28-e5ed-4475-8ea7-51bf2d5df139"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/drive/MyDrive/Google AI Studio/forest.jpg'\n",
        "image = Image.open(image_path)\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vuK7wowXY9b0",
        "outputId": "789dd1c2-eec6-42c1-8b52-caf346617b3e"
      },
      "outputs": [],
      "source": [
        "prompt[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZzfAEQCMkwV"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/MyDrive/MODELS/Phi-3.5-vision-instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ab507688e45b4651a0da26c360a2fbd7",
            "8b214f3b29fc4a33b23f56b4a87174e3",
            "d5327314a8244e01b37d30e49da6d515",
            "88d2425f7e784d32a0804d9f02acc069",
            "686cebc2178140198d51c01bf34e5511",
            "827bfa85364f46ff9d6fdeff0c40e830",
            "3ed5cfae3b3141e48a1875bfba1bba7a",
            "db3b25b43ae94406a541ba16ed15fcb8",
            "8a945a1be93549bb843606713de9a217",
            "abad18c0c28848e38ea126d820d7c4b7",
            "ee72f81062e84376b57b4bc1917a3546"
          ]
        },
        "id": "yQC9WnZrTrzL",
        "outputId": "3a31b899-3ffc-4c6d-bcb1-2936cd344417"
      },
      "outputs": [],
      "source": [
        "model = CustomLLMChat(model_path=model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IuVa77FgVPbh",
        "outputId": "2467619b-1c5d-4fc9-de2c-dec8e4a660dd"
      },
      "outputs": [],
      "source": [
        "prompt[0].metadata[\"image_path\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc9raQSRX4Cp"
      },
      "outputs": [],
      "source": [
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Viie_-dYVEwu",
        "outputId": "26377979-ea4f-49b1-d888-69a2011ad690"
      },
      "outputs": [],
      "source": [
        "result = model.invoke(prompt)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpo_po1RbNtp",
        "outputId": "3f52f996-c441-4a4d-cc5c-d10303e3ab24"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n11WwLxsvaMj"
      },
      "outputs": [],
      "source": [
        "result2 =await model.ainvoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev8rlbBdvm4z",
        "outputId": "8c305ca2-640b-45dd-ae45-ade4d112dc37"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(result2.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqANoQcUPu_6",
        "outputId": "9acad3f2-cedb-41e8-95a3-40f8b38aef9b"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svxWpnm7q15j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import  AutoTokenizer\n",
        "from typing import Any, Dict, List, Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXSOvjguqs8d"
      },
      "outputs": [],
      "source": [
        "class CustomLLMChat2(BaseChatModel):\n",
        "\n",
        "    model_name: str = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "    tokenizer : AutoTokenizer = None\n",
        "    model: AutoModelForCausalLM = None\n",
        "    model_path: str = None\n",
        "\n",
        "    def __init__(self, model_path, **kwargs: Any) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "        if model_path is not None:\n",
        "            self.model_name = model_path\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_name, trust_remote_code=True, torch_dtype=\"auto\", device_map=\"cuda:0\"\n",
        "        )\n",
        "\n",
        "\n",
        "    def _call(\n",
        "            self,\n",
        "            prompt: str,\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> str:\n",
        "        # Load and preprocess the image\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        model_inputs  = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
        "        generated_ids = self.model.generate(\n",
        "              **model_inputs,\n",
        "              max_new_tokens=512\n",
        "          )\n",
        "        generated_ids = [\n",
        "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "          ]\n",
        "\n",
        "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        return response\n",
        "\n",
        "    async def _acall(\n",
        "            self,\n",
        "            prompt: str,\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> str:\n",
        "        # Implement the async logic to generate a response from the model\n",
        "        return await run_in_executor(\n",
        "            None,\n",
        "            self._call,\n",
        "            prompt,\n",
        "            stop,\n",
        "            run_manager.get_sync() if run_manager else None,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom-llm-chat\"\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Dict[str, Any]:\n",
        "        return {\"model_name\": self.model_name}\n",
        "\n",
        "    def _generate(\n",
        "            self,\n",
        "            messages: List[BaseMessage],\n",
        "            stop: Optional[List[str]] = None,\n",
        "            run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "            **kwargs: Any,\n",
        "    ) -> ChatResult:\n",
        "        # Assumes the first message contains the prompt and the image path is in metadata\n",
        "        prompt = messages[0].content\n",
        "        response_text = self._call(prompt,  stop, run_manager, **kwargs)\n",
        "\n",
        "        # Create AIMessage with the response\n",
        "        ai_message = AIMessage(content=response_text)\n",
        "        return ChatResult(generations=[ChatGeneration(message=ai_message)])\n",
        "\n",
        "\n",
        "def create_prompt_chat(message: str ) -> List[BaseMessage]:\n",
        "\n",
        "    assistant_prompt = '<|assistant|>\\n'\n",
        "\n",
        "    prompt = f\"{message}{assistant_prompt}\"\n",
        "\n",
        "    return [HumanMessage(content=prompt)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVWcePUItl4k"
      },
      "outputs": [],
      "source": [
        "prompt2 = create_prompt_chat(\"How to explain Internet for a medieval knight?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HraJmFzuOMW"
      },
      "outputs": [],
      "source": [
        "model_path_2 = \"/content/drive/MyDrive/MODELS/Qwen2.5-1.5B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hngWPzL9twnC"
      },
      "outputs": [],
      "source": [
        "model2= CustomLLMChat2(model_path=model_path_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pxghQ8GA6k1n",
        "outputId": "2e04ae41-3fe9-4537-ea3c-558de51a0ad7"
      },
      "outputs": [],
      "source": [
        "model2._llm_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-CQkaI6qQ1",
        "outputId": "3229178c-08d8-4381-e6cf-852e9913b78f"
      },
      "outputs": [],
      "source": [
        "model2._identifying_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BFswJs-g6v-Y",
        "outputId": "5b959a3d-1f15-4412-852c-ac716bf5dc45"
      },
      "outputs": [],
      "source": [
        "model2.model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnY91vBn2U5b"
      },
      "outputs": [],
      "source": [
        "result = model2.invoke(prompt2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvvfZc6E2qCD",
        "outputId": "fc091f4f-38e5-47bb-e9fa-ffebf998cca9"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T60-xuqb3Cn9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko7ocvz53CjV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNyxbUXu1F/ZbdedYAfd/jc",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ed5cfae3b3141e48a1875bfba1bba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686cebc2178140198d51c01bf34e5511": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827bfa85364f46ff9d6fdeff0c40e830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d2425f7e784d32a0804d9f02acc069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abad18c0c28848e38ea126d820d7c4b7",
            "placeholder": "​",
            "style": "IPY_MODEL_ee72f81062e84376b57b4bc1917a3546",
            "value": " 2/2 [00:07&lt;00:00,  3.48s/it]"
          }
        },
        "8a945a1be93549bb843606713de9a217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b214f3b29fc4a33b23f56b4a87174e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_827bfa85364f46ff9d6fdeff0c40e830",
            "placeholder": "​",
            "style": "IPY_MODEL_3ed5cfae3b3141e48a1875bfba1bba7a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ab507688e45b4651a0da26c360a2fbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b214f3b29fc4a33b23f56b4a87174e3",
              "IPY_MODEL_d5327314a8244e01b37d30e49da6d515",
              "IPY_MODEL_88d2425f7e784d32a0804d9f02acc069"
            ],
            "layout": "IPY_MODEL_686cebc2178140198d51c01bf34e5511"
          }
        },
        "abad18c0c28848e38ea126d820d7c4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5327314a8244e01b37d30e49da6d515": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3b25b43ae94406a541ba16ed15fcb8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a945a1be93549bb843606713de9a217",
            "value": 2
          }
        },
        "db3b25b43ae94406a541ba16ed15fcb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee72f81062e84376b57b4bc1917a3546": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
