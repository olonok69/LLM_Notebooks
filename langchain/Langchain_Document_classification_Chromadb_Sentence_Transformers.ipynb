{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olonok69/LLM_Notebooks/blob/main/langchain/Langchain_Document_classification_Chromadb_Sentence_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3LFaHkF9AgK",
        "outputId": "777994ea-77de-4b2e-fca7-50cdb0da7f1b"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.34.0 --progress-bar off\n",
        "!pip install -qqq accelerate==0.23.0 --progress-bar off\n",
        "!pip install -qqq bitsandbytes==0.41.1 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veaIAYHJQJCv",
        "outputId": "331a69d9-9e29-4697-8698-222d49438f30"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers spacy langchain trl datasets pypdf jq html2text  chromadb unstructured -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bWjwt10IjNu"
      },
      "source": [
        "# Chromadb\n",
        "\n",
        "Chroma is the open-source embedding database. Chroma makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs.\n",
        "\n",
        "https://docs.trychroma.com/\n",
        "\n",
        "https://python.langchain.com/docs/integrations/vectorstores/chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip_uhu9L9kof"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, AutoModelForCausalLM\n",
        "import torch\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import transformers\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "import chromadb\n",
        "import pandas as pd\n",
        "from chromadb.utils import embedding_functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6rUNtCzKsyR",
        "outputId": "5bb85a9c-c3c8-43f4-906c-c0e49964f0dc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxPVavEf9klX"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/drive/MyDrive/data/doc_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZbY6VOYHP4i"
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "#embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L12-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oW2wOAzidqh",
        "outputId": "067ed5c3-ea5f-4719-962c-445857f91449"
      },
      "outputs": [],
      "source": [
        "model_name='sentence-transformers/gtr-t5-large'#'google/flan-t5-large'\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-56EaYypJePV"
      },
      "source": [
        "# Langchain DirectoryLoader\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/document_loaders/file_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ-RiNgRZPlM"
      },
      "outputs": [],
      "source": [
        "txt_loader = DirectoryLoader(path = data_path , glob = '*.txt', recursive=True)\n",
        "docs = txt_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZyth_yb9kiL",
        "outputId": "dfea7097-0584-41da-c343-9736021f61d9"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HFrX0PiIREa",
        "outputId": "2e926baf-0bbb-4e56-8a19-259ca9a1f384"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOzbh9bSM4zJ"
      },
      "outputs": [],
      "source": [
        "# Text Summarization Pipeline\n",
        "text_summarization_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"summarization\",\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "      max_new_tokens=2000,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "\n",
        "\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=text_summarization_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "um-qU1-KRO6e",
        "outputId": "1c946cb3-7522-440f-ca03-d997fcbaab53"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQiwrBYFM76m",
        "outputId": "f8e5f292-6555-4377-dd49-4a42fb9da259"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "    num_tokens = llm.get_num_tokens(doc.page_content)\n",
        "    print (f\"file{doc.metadata['source']} has {num_tokens} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0niM4btPhOF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from chromadb.utils import embedding_functions\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wOl5CBGPp4D"
      },
      "outputs": [],
      "source": [
        "purview_classes_path = \"/content/drive/MyDrive/data/Microsoft_Purview_Classifiers_with_ddg_to_load.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GA8KqTnM1vJ"
      },
      "source": [
        "# Sentence Transformers\n",
        "\n",
        "https://huggingface.co/sentence-transformers\n",
        "\n",
        "# sentence-transformers/gtr-t5-large\n",
        "\n",
        "https://huggingface.co/sentence-transformers/gtr-t5-large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2MxtE9SNKvt"
      },
      "outputs": [],
      "source": [
        "#chroma_client.delete_collection(name=\"purview_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6nR9TgSRD8y"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "chroma_path = \"/content/drive/MyDrive/chroma_persistence\"\n",
        "#delete collection if this exists\n",
        "\n",
        "\n",
        "\n",
        "model_name = \"sentence-transformers/gtr-t5-large\"\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "\n",
        "#creating a new collection , cosine similarity it will be the metrics to measure similitude\n",
        "#collection = chroma_client.create_collection(name=\"purview_data\")#, metadata={\"hnsw:space\": \"cosine\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwQNTrtYJsLg"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "\n",
        "# Load data from a CSV file using CSVLoader\n",
        "loader = CSVLoader(purview_classes_path, metadata_columns=[\"classifier\"])\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "tuvGU8P1o7YA",
        "outputId": "e6d39f9d-7066-4f98-b095-83701d81183a"
      },
      "outputs": [],
      "source": [
        "documents[0].page_content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dmS4m1SN3Oy"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(documents=documents,\n",
        "\n",
        "                                 # Chose the embedding you want to use\n",
        "                                 embedding=hf,\n",
        "                                 collection_metadata = {\"hnsw:space\": \"cosine\"},\n",
        "                                 persist_directory=chroma_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHKOFxpsOwbF"
      },
      "outputs": [],
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfqXe5CpO4Pf"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma(persist_directory=chroma_path,\n",
        "                  embedding_function=hf\n",
        "\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANz0XBbtRbv-"
      },
      "source": [
        "The similarity_search_with_score function in LangChain with Chroma DB returns higher scores for less relevant documents because it uses cosine distance as the scoring metric. In cosine distance, a lower score indicates a higher similarity between the query and the document. Therefore, documents with lower scores are more relevant to the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjCHPer1TBe_"
      },
      "outputs": [],
      "source": [
        "res = vectordb.similarity_search(docs[100].page_content, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLjWpxVYUe86",
        "outputId": "fcacedca-636b-43a8-a1c9-9bdfdcdb7190"
      },
      "outputs": [],
      "source": [
        "for doc in res:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Class {doc.metadata.get('classifier')}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7UsDX0API3O"
      },
      "outputs": [],
      "source": [
        "docs_with_score = vectordb.similarity_search_with_score(docs[100].page_content, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrXuu6MPPf7R",
        "outputId": "e6251fda-f4be-4576-fda0-c0ba07e7b61f"
      },
      "outputs": [],
      "source": [
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Class {doc.metadata.get('classifier')}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "5qvsqDdfPsxf",
        "outputId": "181ec32f-847d-4752-d8d8-695a46f43b6f"
      },
      "outputs": [],
      "source": [
        "docs[100].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqpKU25rVTwn",
        "outputId": "31bc1c31-7cfb-4200-f42b-bd4a57695db9"
      },
      "outputs": [],
      "source": [
        "vectordb.embeddings"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMPrR4m9FdDbQ0EzTdXfYjm",
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "mount_file_id": "18QUcyh882caiSWz8HNL6mnQocSP8jjhG",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
